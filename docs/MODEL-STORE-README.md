# Fleet Navigator Model Store - Anleitung

## âœ¨ Was wurde implementiert?

Die vollstÃ¤ndige **Modellverwaltung mit Download-FunktionalitÃ¤t** fÃ¼r llama.cpp ist jetzt verfÃ¼gbar!

### ğŸ¯ Features

- âœ… **Model Store** mit 9 kuratierten deutschen GGUF-Modellen
- âœ… **Direkter Download** von HuggingFace
- âœ… **Echtzeit-Progress** mit Download-Geschwindigkeit
- âœ… **Modell-Filter** nach Kategorie, RAM und Sprache
- âœ… **Neue Verzeichnisstruktur** fÃ¼r bessere Organisation
- âœ… **Deutsche Modelle** optimiert fÃ¼r deutsche Texte

---

## ğŸ“ Neue Verzeichnisstruktur

```
models/
â”œâ”€â”€ library/          â† Heruntergeladene Modelle aus dem Store
â”‚   â””â”€â”€ (leer am Anfang)
â”œâ”€â”€ custom/           â† Eigene hochgeladene Modelle
â”‚   â””â”€â”€ Llama-3.2-1B-Instruct-Q4_K_M.gguf (dein existierendes Modell)
```

**Wichtig:** Dein bestehendes Modell wurde automatisch nach `models/custom/` verschoben!

---

## ğŸª VerfÃ¼gbare Modelle im Store

### â­ Empfohlen fÃ¼r deutsche Texte:

1. **Qwen 2.5 (3B) - Instruct** - 1.97 GB
   - Exzellentes mehrsprachiges Modell
   - Hervorragendes Deutsch
   - Perfekt fÃ¼r: Briefe, E-Mails, Chat
   - Min RAM: 4 GB

2. **Llama 3.2 (3B) - Instruct** - 2.02 GB
   - Schnelles Allzweck-Modell
   - Gutes Deutsch
   - Perfekt fÃ¼r: Chat, Q&A
   - Min RAM: 4 GB

3. **Qwen 2.5 (7B) - Instruct** - 4.73 GB
   - Premium-Modell
   - Exzellente QualitÃ¤t
   - Perfekt fÃ¼r: Komplexe Texte, Analyse
   - Min RAM: 8 GB

### ğŸ’» FÃ¼r Code-Generierung:

4. **Qwen 2.5 Coder (3B)** - 1.97 GB
   - Spezialisiert auf Code
   - Versteht deutsche Anweisungen
   - Min RAM: 4 GB

5. **Qwen 2.5 Coder (7B)** - 4.73 GB
   - Premium Code-Modell
   - HÃ¶chste QualitÃ¤t
   - Min RAM: 8 GB

### ğŸ“¦ Kompakte Modelle (fÃ¼r schwache Hardware):

6. **Llama 3.2 (1B)** - 771 MB (bereits vorhanden)
7. **Qwen 2.5 (1.5B)** - 1.05 GB

---

## ğŸš€ Wie du Modelle herunterlÃ¤dst

### Schritt 1: Fleet Navigator starten

```bash
cd /home/trainer/NetBeansProjects/ProjekteFMH/Fleet-Navigator
./START.sh
```

### Schritt 2: Model Store Ã¶ffnen

1. Ã–ffne die Anwendung: http://localhost:5173
2. Klicke auf **âš™ï¸ Einstellungen** (unten links)
3. WÃ¤hle den Tab **ğŸª Model Store**

### Schritt 3: Modell auswÃ¤hlen

- **Empfohlene Modelle** werden oben angezeigt
- Filtere nach:
  - **Kategorie**: Chat, Code, Kompakt
  - **RAM**: Max 4 GB, 8 GB, 16 GB
  - **Suche**: Nach Namen oder Sprache

### Schritt 4: Download starten

1. Klicke auf **â¬‡ï¸ Herunterladen** bei deinem gewÃ¼nschten Modell
2. Beobachte den **Echtzeit-Progress**:
   - Prozent-Anzeige
   - Download-Geschwindigkeit (MB/s)
   - Verbleibende Zeit

3. **Active Downloads Panel** unten rechts zeigt alle laufenden Downloads

### Schritt 5: Fertig!

- Nach dem Download ist das Modell sofort verfÃ¼gbar
- Es erscheint als **âœ“ Installiert**
- Du kannst es direkt im Chat verwenden

---

## ğŸ¯ Empfehlung fÃ¼r dich

### FÃ¼r den Einstieg (Deutsch):

**Qwen 2.5 (3B) - Instruct** herunterladen:
- Nur **1.97 GB**
- Exzellentes Deutsch
- Schnell und effizient
- Perfekt fÃ¼r Briefe und E-Mails

### Falls du mehr Power willst:

**Qwen 2.5 (7B) - Instruct** herunterladen:
- **4.73 GB**
- Beste QualitÃ¤t
- FÃ¼r komplexe Aufgaben
- BenÃ¶tigt min. 8 GB RAM

---

## ğŸ” Technische Details

### Backend-Komponenten

Neu implementiert:
- `ModelRegistry.java` - 9 kuratierte Modelle
- `ModelRegistryEntry.java` - Modell-Metadata
- `ModelDownloadService.java` - HuggingFace Download mit Progress
- `ModelStoreController.java` - REST API fÃ¼r Model Store
- `LlamaCppProvider.java` - Erweitert um neue Verzeichnisstruktur

### Frontend-Komponenten

Neu implementiert:
- `ModelStore.vue` - Hauptkomponente mit Filter
- `ModelCard.vue` - Modell-Anzeige mit Download-Button
- Integration in `SettingsModal.vue` als neuer Tab

### API Endpoints

```
GET  /api/model-store/all              â†’ Alle Modelle
GET  /api/model-store/featured         â†’ Empfohlene Modelle
GET  /api/model-store/category/{cat}   â†’ Nach Kategorie
GET  /api/model-store/download/{id}    â†’ Download mit SSE Progress
POST /api/model-store/download/{id}/cancel â†’ Download abbrechen
```

---

## ğŸ§ª Testen

### Download-Test:

1. Starte Fleet Navigator
2. Ã–ffne Model Store
3. WÃ¤hle ein kleines Modell (z.B. Qwen 2.5 1.5B - 1.05 GB)
4. Klicke Download
5. Beobachte den Progress

**Erwartet:**
- Download startet sofort
- Progress-Updates alle 500ms
- Geschwindigkeit in MB/s
- Nach Download: âœ“ Installiert

### Verzeichnis-Check:

```bash
ls -lh models/library/
ls -lh models/custom/
```

**Erwartet:**
- `library/` enthÃ¤lt heruntergeladene Modelle
- `custom/` enthÃ¤lt dein existierendes Llama-3.2-1B Modell

---

## â“ Probleme?

### Download startet nicht

1. PrÃ¼fe Internet-Verbindung
2. PrÃ¼fe Backend-Logs: `mvn spring-boot:run`
3. PrÃ¼fe Browser-Console (F12)

### Download zu langsam

- HuggingFace kann bei groÃŸen Modellen Zeit brauchen
- Geschwindigkeit hÃ¤ngt von deiner Internet-Verbindung ab
- Du kannst den Download abbrechen und spÃ¤ter fortsetzen

### Modell erscheint nicht

1. PrÃ¼fe `models/library/` Verzeichnis
2. Klicke auf **ğŸ”„ Aktualisieren** im Model Store
3. Starte Fleet Navigator neu

---

## ğŸ‰ Viel Erfolg!

Du kannst jetzt direkt aus Fleet Navigator heraus hochwertige deutsche GGUF-Modelle herunterladen!

**Empfehlung:** Start mit **Qwen 2.5 (3B)** - das ist das beste Preis-Leistungs-VerhÃ¤ltnis fÃ¼r deutsche Texte.

---

**Erstellt:** 2025-11-11
**Version:** 0.2.9
**Autor:** JavaFleet Systems Consulting
